{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from data.data import get_train_test_loader\n",
    "from model.network import FastUpdateNet_CNet, TeacherNet\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.0005\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "# torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_train_test_loader('mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "\n",
    "def do(network):\n",
    "  network.mNet.backwardHidden() \n",
    "\n",
    "def train_fastNet(epoch, network):\n",
    "  network.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = network(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    network.cNet.backwardHidden() \n",
    "    network.cNet.train_c()\n",
    "    correctness = (target == torch.argmax(output))\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append(\n",
    "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "\n",
    "\n",
    "def train_teacherNet(epoch, network):\n",
    "  network.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = network(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    # print(network.mNet.saver.grad)\n",
    "    correctness = (target == torch.argmax(output))\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append(\n",
    "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(network):\n",
    "  network.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      output = network(data)\n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "  test_accuracies.append(100. * correct / len(test_loader.dataset))\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with inv\n",
    "error tensor(0.0003, grad_fn=<SumBackward0>)\n",
    "0.018805503845214844\n",
    "\n",
    "with pinv\n",
    "error tensor(0.00004, grad_fn=<SumBackward0>)\n",
    "0.02195906639099121\n",
    "\n",
    "0.01661086082458496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hao/Documents/magic-m/model/network.py:328: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(o_4)\n",
      "/home/hao/miniconda/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3057, Accuracy: 942/10000 (9%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.2997, Accuracy: 985/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.2942, Accuracy: 1282/10000 (13%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.2876, Accuracy: 2431/10000 (24%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.2794, Accuracy: 2713/10000 (27%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.2676, Accuracy: 3292/10000 (33%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.2533, Accuracy: 4083/10000 (41%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.2544, Accuracy: 2337/10000 (23%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.1791, Accuracy: 2060/10000 (21%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.0658, Accuracy: 1909/10000 (19%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.8662, Accuracy: 3674/10000 (37%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.5992, Accuracy: 4680/10000 (47%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.5600, Accuracy: 4711/10000 (47%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.6277, Accuracy: 4454/10000 (45%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.6130, Accuracy: 4543/10000 (45%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.3981, Accuracy: 5210/10000 (52%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.2822, Accuracy: 5728/10000 (57%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.2102, Accuracy: 5892/10000 (59%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.1550, Accuracy: 5918/10000 (59%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.0758, Accuracy: 6467/10000 (65%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9434, Accuracy: 6889/10000 (69%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8468, Accuracy: 7327/10000 (73%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7551, Accuracy: 7866/10000 (79%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6728, Accuracy: 8027/10000 (80%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5967, Accuracy: 8132/10000 (81%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5447, Accuracy: 8187/10000 (82%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5006, Accuracy: 8258/10000 (83%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4617, Accuracy: 8395/10000 (84%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4366, Accuracy: 8389/10000 (84%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4120, Accuracy: 8488/10000 (85%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3896, Accuracy: 8716/10000 (87%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3724, Accuracy: 8882/10000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3543, Accuracy: 8994/10000 (90%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3318, Accuracy: 9155/10000 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3099, Accuracy: 9204/10000 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2965, Accuracy: 9296/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2817, Accuracy: 9331/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2701, Accuracy: 9361/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2549, Accuracy: 9388/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2521, Accuracy: 9373/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2564, Accuracy: 9361/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2442, Accuracy: 9385/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2404, Accuracy: 9385/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2497, Accuracy: 9360/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2487, Accuracy: 9379/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2510, Accuracy: 9336/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2530, Accuracy: 9339/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2575, Accuracy: 9322/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2603, Accuracy: 9330/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2637, Accuracy: 9286/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2464, Accuracy: 9367/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2566, Accuracy: 9291/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2482, Accuracy: 9334/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2428, Accuracy: 9362/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2460, Accuracy: 9370/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2434, Accuracy: 9385/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2643, Accuracy: 9280/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2794, Accuracy: 9219/10000 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2402, Accuracy: 9352/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2454, Accuracy: 9329/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2382, Accuracy: 9389/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2388, Accuracy: 9367/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2353, Accuracy: 9362/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2398, Accuracy: 9371/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2396, Accuracy: 9352/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2443, Accuracy: 9344/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2417, Accuracy: 9339/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2359, Accuracy: 9373/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2358, Accuracy: 9362/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2444, Accuracy: 9381/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2387, Accuracy: 9415/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2431, Accuracy: 9379/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2478, Accuracy: 9360/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2646, Accuracy: 9317/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2721, Accuracy: 9263/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2629, Accuracy: 9340/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2702, Accuracy: 9313/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2564, Accuracy: 9357/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2887, Accuracy: 9196/10000 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2478, Accuracy: 9490/10000 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2478, Accuracy: 9439/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2423, Accuracy: 9423/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2295, Accuracy: 9476/10000 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2371, Accuracy: 9438/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2609, Accuracy: 9380/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2523, Accuracy: 9410/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2501, Accuracy: 9401/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2412, Accuracy: 9443/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2396, Accuracy: 9441/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2466, Accuracy: 9422/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2518, Accuracy: 9397/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2511, Accuracy: 9428/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2668, Accuracy: 9366/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2694, Accuracy: 9232/10000 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2391, Accuracy: 9451/10000 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2444, Accuracy: 9408/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2338, Accuracy: 9448/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2326, Accuracy: 9462/10000 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2220, Accuracy: 9457/10000 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2316, Accuracy: 9466/10000 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2333, Accuracy: 9431/10000 (94%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "cNet = FastUpdateNet_CNet()\n",
    "optimizer = optim.SGD(cNet.get_parameters(), lr=learning_rate, momentum=momentum)\n",
    "test(cNet)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train_fastNet(epoch, cNet)\n",
    "  test(cNet)\n",
    "  if test_accuracies[-1] > 0.1:\n",
    "    cNet.cNet.useC = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3114, Accuracy: 917/10000 (9%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.3055, Accuracy: 1028/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.2998, Accuracy: 1012/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.2929, Accuracy: 1010/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.2846, Accuracy: 1037/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.2739, Accuracy: 1312/10000 (13%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.2560, Accuracy: 1578/10000 (16%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.2781, Accuracy: 1025/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.2788, Accuracy: 664/10000 (7%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.2839, Accuracy: 1231/10000 (12%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.2490, Accuracy: 1563/10000 (16%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.0521, Accuracy: 2066/10000 (21%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.8133, Accuracy: 3450/10000 (34%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.6218, Accuracy: 4459/10000 (45%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.6504, Accuracy: 4428/10000 (44%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.5401, Accuracy: 5584/10000 (56%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.3491, Accuracy: 5820/10000 (58%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.1743, Accuracy: 6088/10000 (61%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.1837, Accuracy: 5689/10000 (57%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.1764, Accuracy: 5784/10000 (58%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.1154, Accuracy: 6305/10000 (63%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.0448, Accuracy: 6838/10000 (68%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9597, Accuracy: 7201/10000 (72%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8863, Accuracy: 7318/10000 (73%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8671, Accuracy: 7521/10000 (75%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9231, Accuracy: 7415/10000 (74%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8873, Accuracy: 7723/10000 (77%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8773, Accuracy: 7688/10000 (77%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7729, Accuracy: 8082/10000 (81%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7487, Accuracy: 8081/10000 (81%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6966, Accuracy: 8205/10000 (82%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6461, Accuracy: 8328/10000 (83%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6256, Accuracy: 8386/10000 (84%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6042, Accuracy: 8386/10000 (84%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6144, Accuracy: 8192/10000 (82%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6274, Accuracy: 7989/10000 (80%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6656, Accuracy: 7648/10000 (76%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7203, Accuracy: 7643/10000 (76%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6035, Accuracy: 8127/10000 (81%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5509, Accuracy: 8232/10000 (82%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5139, Accuracy: 8298/10000 (83%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4971, Accuracy: 8343/10000 (83%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4767, Accuracy: 8317/10000 (83%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4542, Accuracy: 8740/10000 (87%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4471, Accuracy: 8816/10000 (88%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4200, Accuracy: 8886/10000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4078, Accuracy: 8895/10000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4290, Accuracy: 8806/10000 (88%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4339, Accuracy: 8742/10000 (87%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3905, Accuracy: 8952/10000 (90%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3848, Accuracy: 8966/10000 (90%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3767, Accuracy: 9013/10000 (90%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3791, Accuracy: 8989/10000 (90%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4276, Accuracy: 8695/10000 (87%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4430, Accuracy: 8471/10000 (85%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4250, Accuracy: 8452/10000 (85%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4039, Accuracy: 8901/10000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3603, Accuracy: 9104/10000 (91%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3562, Accuracy: 9066/10000 (91%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3326, Accuracy: 9157/10000 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3318, Accuracy: 9077/10000 (91%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3318, Accuracy: 9104/10000 (91%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3368, Accuracy: 9057/10000 (91%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3252, Accuracy: 9119/10000 (91%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3184, Accuracy: 9176/10000 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3169, Accuracy: 9194/10000 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3088, Accuracy: 9202/10000 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3241, Accuracy: 9161/10000 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3159, Accuracy: 9154/10000 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3149, Accuracy: 9166/10000 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3043, Accuracy: 9195/10000 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2938, Accuracy: 9213/10000 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3022, Accuracy: 9211/10000 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2880, Accuracy: 9199/10000 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2804, Accuracy: 9244/10000 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2710, Accuracy: 9292/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2655, Accuracy: 9298/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2777, Accuracy: 9254/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2632, Accuracy: 9302/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2554, Accuracy: 9307/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2611, Accuracy: 9289/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2521, Accuracy: 9314/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2777, Accuracy: 9258/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2557, Accuracy: 9328/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2533, Accuracy: 9254/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4426, Accuracy: 8834/10000 (88%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3410, Accuracy: 9101/10000 (91%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2863, Accuracy: 9244/10000 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2684, Accuracy: 9300/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2610, Accuracy: 9312/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2524, Accuracy: 9351/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2499, Accuracy: 9350/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2352, Accuracy: 9388/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2402, Accuracy: 9403/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2341, Accuracy: 9407/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2429, Accuracy: 9351/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2448, Accuracy: 9394/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2641, Accuracy: 9307/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2577, Accuracy: 9318/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2863, Accuracy: 9227/10000 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2941, Accuracy: 9245/10000 (92%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "cNet = FastUpdateNet_CNet()\n",
    "optimizer = optim.SGD(cNet.get_parameters(), lr=learning_rate, momentum=momentum)\n",
    "test(cNet)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train_fastNet(epoch, cNet)\n",
    "  test(cNet)\n",
    "  if test_accuracies[-1] > 0.5:\n",
    "    cNet.cNet.useC = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3070, Accuracy: 974/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.3020, Accuracy: 1064/10000 (11%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.2966, Accuracy: 2148/10000 (21%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.2902, Accuracy: 2688/10000 (27%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.2810, Accuracy: 2476/10000 (25%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.2648, Accuracy: 2243/10000 (22%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.2224, Accuracy: 2192/10000 (22%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.0933, Accuracy: 2239/10000 (22%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.0115, Accuracy: 2401/10000 (24%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.8855, Accuracy: 3631/10000 (36%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.6147, Accuracy: 5329/10000 (53%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.2917, Accuracy: 6253/10000 (63%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.1024, Accuracy: 6400/10000 (64%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.1378, Accuracy: 6064/10000 (61%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.0371, Accuracy: 6562/10000 (66%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.3194, Accuracy: 5781/10000 (58%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.3834, Accuracy: 5787/10000 (58%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.2972, Accuracy: 6051/10000 (61%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.2088, Accuracy: 6376/10000 (64%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.2242, Accuracy: 6162/10000 (62%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.2114, Accuracy: 6139/10000 (61%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.1707, Accuracy: 6795/10000 (68%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.1229, Accuracy: 6680/10000 (67%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.0041, Accuracy: 6650/10000 (66%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9926, Accuracy: 6850/10000 (68%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9837, Accuracy: 6835/10000 (68%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9505, Accuracy: 6979/10000 (70%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8790, Accuracy: 7038/10000 (70%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7976, Accuracy: 7467/10000 (75%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7283, Accuracy: 7862/10000 (79%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6885, Accuracy: 8029/10000 (80%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6998, Accuracy: 7789/10000 (78%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5943, Accuracy: 8235/10000 (82%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5464, Accuracy: 8456/10000 (85%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5186, Accuracy: 8497/10000 (85%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5107, Accuracy: 8496/10000 (85%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4771, Accuracy: 8619/10000 (86%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5017, Accuracy: 8533/10000 (85%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4540, Accuracy: 8692/10000 (87%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4257, Accuracy: 8790/10000 (88%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4162, Accuracy: 8777/10000 (88%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3914, Accuracy: 8865/10000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3938, Accuracy: 8844/10000 (88%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3844, Accuracy: 8886/10000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3808, Accuracy: 8898/10000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3731, Accuracy: 8929/10000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3859, Accuracy: 8859/10000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3829, Accuracy: 8878/10000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3906, Accuracy: 8884/10000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3935, Accuracy: 8818/10000 (88%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3814, Accuracy: 8881/10000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4286, Accuracy: 8700/10000 (87%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4180, Accuracy: 8745/10000 (87%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3842, Accuracy: 8876/10000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3938, Accuracy: 8827/10000 (88%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3927, Accuracy: 8818/10000 (88%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3877, Accuracy: 8833/10000 (88%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4057, Accuracy: 8754/10000 (88%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4036, Accuracy: 8763/10000 (88%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4573, Accuracy: 8592/10000 (86%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4183, Accuracy: 8704/10000 (87%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3977, Accuracy: 8796/10000 (88%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3842, Accuracy: 8842/10000 (88%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4003, Accuracy: 8769/10000 (88%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4482, Accuracy: 8613/10000 (86%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4340, Accuracy: 8663/10000 (87%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4553, Accuracy: 8582/10000 (86%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4221, Accuracy: 8706/10000 (87%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3839, Accuracy: 8862/10000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4001, Accuracy: 8802/10000 (88%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3921, Accuracy: 8822/10000 (88%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4293, Accuracy: 8688/10000 (87%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4407, Accuracy: 8618/10000 (86%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4068, Accuracy: 8745/10000 (87%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4255, Accuracy: 8661/10000 (87%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4089, Accuracy: 8711/10000 (87%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3894, Accuracy: 8803/10000 (88%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3898, Accuracy: 8805/10000 (88%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4199, Accuracy: 8679/10000 (87%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4671, Accuracy: 8481/10000 (85%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4057, Accuracy: 8739/10000 (87%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3864, Accuracy: 8760/10000 (88%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3647, Accuracy: 8871/10000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3394, Accuracy: 8920/10000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3365, Accuracy: 8915/10000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3255, Accuracy: 8982/10000 (90%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3685, Accuracy: 8831/10000 (88%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3422, Accuracy: 8909/10000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3510, Accuracy: 8895/10000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3366, Accuracy: 8928/10000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3041, Accuracy: 9063/10000 (91%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2876, Accuracy: 9134/10000 (91%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3062, Accuracy: 9086/10000 (91%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2823, Accuracy: 9171/10000 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2656, Accuracy: 9220/10000 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2607, Accuracy: 9216/10000 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2521, Accuracy: 9249/10000 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2489, Accuracy: 9260/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2499, Accuracy: 9253/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2337, Accuracy: 9292/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2333, Accuracy: 9320/10000 (93%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "cNet = FastUpdateNet_CNet()\n",
    "optimizer = optim.SGD(cNet.get_parameters(), lr=learning_rate, momentum=momentum)\n",
    "test(cNet)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train_fastNet(epoch, cNet)\n",
    "  test(cNet)\n",
    "  if test_accuracies[-1] > 0.7:\n",
    "    cNet.cNet.useC = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2209365180.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [10]\u001b[0;36m\u001b[0m\n\u001b[0;31m    Test set: Avg. loss: 0.1158, Accuracy: 9649/10000 (96%) # no warm up\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Test set: Avg. loss: 0.1158, Accuracy: 9649/10000 (96%) # no warm up\n",
    "Test set: Avg. loss: 0.1035, Accuracy: 9680/10000 (97%) # 0.5\n",
    "Test set: Avg. loss: 0.1080, Accuracy: 9703/10000 (97%) # 0.7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ee5443183715725406fd5246e657c0e511f90699501bc5e8c5d8d2b3c204bfa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
