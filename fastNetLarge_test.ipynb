{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from data.data import get_train_test_loader\n",
    "from model.network import FastUpdateNet, FastUpdateNetLarge, TeacherNetLarge\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pickle\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "# torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_train_test_loader('fashionmnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "\n",
    "def compute_back_M1(network):\n",
    "  network.mNet1.backwardHidden()\n",
    "\n",
    "def compute_back_M2(network):\n",
    "  network.mNet2.backwardHidden()\n",
    "\n",
    "def train(epoch, network):\n",
    "  network.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = network(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    # print(network.mNet.saver.grad)\n",
    "    # p1 = Thread(target=compute_back_M1, args=[network]) # start two independent threads\n",
    "    # p2 = Thread(target=compute_back_M2, args=[network])\n",
    "    \n",
    "    # p1.start()\n",
    "    # p2.start()\n",
    "    network.mNet1.backwardHidden()\n",
    "    network.mNet2.backwardHidden()\n",
    "    # p1.join() # wait for the two threads to finish\n",
    "    # return \n",
    "    # p2.join()\n",
    "\n",
    "    correctness = (target == torch.argmax(output))\n",
    "    optimizer.step()\n",
    "    # network.mNet.weightUpdate(correctness, lr = learning_rate)\n",
    "    if batch_idx % log_interval == 0:\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append(\n",
    "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(network):\n",
    "  network.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      output = network(data)\n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "  test_accuracies.append(100. * correct / len(test_loader.dataset))\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_teacherNet(epoch, network):\n",
    "  network.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = network(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    # print(network.mNet.saver.grad)\n",
    "    correctness = (target == torch.argmax(output))\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append(\n",
    "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "\n",
    "def test(network):\n",
    "  network.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      output = network(data)\n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "  test_accuracies.append(100. * correct / len(test_loader.dataset))\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test using 2 Ms (computing grad in main thread and separate thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "fNet = FastUpdateNetLarge()\n",
    "# fNet.mNet1 = torch.nn.Sequential(nn.Linear(392, 196), nn.ReLU(), nn.Linear(196, 98), nn.ReLU(), nn.Linear(98, 49), nn.ReLU())\n",
    "# fNet.mNet2 = torch.nn.Sequential(nn.Linear(392, 196), nn.ReLU(), nn.Linear(196, 98), nn.ReLU(), nn.Linear(98, 49), nn.ReLU())\n",
    "optimizer = optim.SGD(fNet.get_parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model type M trail 0 starts\n",
      "\n",
      "Test set: Avg. loss: 2.3024, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.3002, Accuracy: 2265/10000 (23%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.6839, Accuracy: 3158/10000 (32%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9905, Accuracy: 6330/10000 (63%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7703, Accuracy: 7459/10000 (75%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6502, Accuracy: 7739/10000 (77%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6509, Accuracy: 7629/10000 (76%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9252, Accuracy: 6512/10000 (65%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6284, Accuracy: 7799/10000 (78%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6807, Accuracy: 7637/10000 (76%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6868, Accuracy: 7572/10000 (76%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6001, Accuracy: 7935/10000 (79%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5648, Accuracy: 8004/10000 (80%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5688, Accuracy: 7995/10000 (80%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5815, Accuracy: 7925/10000 (79%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5677, Accuracy: 8014/10000 (80%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5550, Accuracy: 8021/10000 (80%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5701, Accuracy: 7909/10000 (79%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5439, Accuracy: 8027/10000 (80%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5368, Accuracy: 8063/10000 (81%)\n",
      "\n",
      "model type M trail 1 starts\n",
      "\n",
      "Test set: Avg. loss: 2.3026, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.3025, Accuracy: 1002/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.3025, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.3024, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.3023, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.3023, Accuracy: 1114/10000 (11%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.3022, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.3021, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.3019, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.3017, Accuracy: 1100/10000 (11%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.3012, Accuracy: 1342/10000 (13%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.3003, Accuracy: 1842/10000 (18%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.2983, Accuracy: 1888/10000 (19%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.2790, Accuracy: 2718/10000 (27%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.6590, Accuracy: 2909/10000 (29%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.1947, Accuracy: 4980/10000 (50%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9961, Accuracy: 6010/10000 (60%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9164, Accuracy: 6192/10000 (62%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9510, Accuracy: 6096/10000 (61%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.1620, Accuracy: 5031/10000 (50%)\n",
      "\n",
      "model type M trail 2 starts\n",
      "\n",
      "Test set: Avg. loss: 2.3025, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.3022, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.3001, Accuracy: 1005/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.8686, Accuracy: 2300/10000 (23%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.1259, Accuracy: 5150/10000 (52%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6505, Accuracy: 7400/10000 (74%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5163, Accuracy: 8164/10000 (82%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5238, Accuracy: 8074/10000 (81%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4460, Accuracy: 8456/10000 (85%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4913, Accuracy: 8244/10000 (82%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4283, Accuracy: 8555/10000 (86%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3963, Accuracy: 8604/10000 (86%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4233, Accuracy: 8499/10000 (85%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4207, Accuracy: 8533/10000 (85%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4430, Accuracy: 8496/10000 (85%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4042, Accuracy: 8570/10000 (86%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4347, Accuracy: 8504/10000 (85%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4076, Accuracy: 8566/10000 (86%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3733, Accuracy: 8663/10000 (87%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3827, Accuracy: 8657/10000 (87%)\n",
      "\n",
      "model type M trail 3 starts\n",
      "\n",
      "Test set: Avg. loss: 2.3026, Accuracy: 1001/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.3024, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.3020, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.2993, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.7279, Accuracy: 2296/10000 (23%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.0731, Accuracy: 5639/10000 (56%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7359, Accuracy: 7228/10000 (72%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5558, Accuracy: 8089/10000 (81%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5465, Accuracy: 8126/10000 (81%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5195, Accuracy: 8165/10000 (82%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4990, Accuracy: 8285/10000 (83%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5071, Accuracy: 8299/10000 (83%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4833, Accuracy: 8339/10000 (83%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5394, Accuracy: 8063/10000 (81%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4905, Accuracy: 8334/10000 (83%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4780, Accuracy: 8361/10000 (84%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4816, Accuracy: 8393/10000 (84%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4956, Accuracy: 8298/10000 (83%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5248, Accuracy: 8270/10000 (83%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5997, Accuracy: 7967/10000 (80%)\n",
      "\n",
      "model type M trail 4 starts\n",
      "\n",
      "Test set: Avg. loss: 2.3025, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.3024, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.3021, Accuracy: 1178/10000 (12%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.2996, Accuracy: 1496/10000 (15%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.4879, Accuracy: 3024/10000 (30%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.1234, Accuracy: 5962/10000 (60%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7733, Accuracy: 7426/10000 (74%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7100, Accuracy: 7522/10000 (75%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6711, Accuracy: 7747/10000 (77%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6266, Accuracy: 7787/10000 (78%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6784, Accuracy: 7716/10000 (77%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7669, Accuracy: 7292/10000 (73%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5865, Accuracy: 7760/10000 (78%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6328, Accuracy: 7614/10000 (76%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5565, Accuracy: 7940/10000 (79%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5781, Accuracy: 7991/10000 (80%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5535, Accuracy: 8122/10000 (81%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5925, Accuracy: 7932/10000 (79%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4572, Accuracy: 8432/10000 (84%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4301, Accuracy: 8473/10000 (85%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net = None\n",
    "optimizer = None\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "net_types = ['M']\n",
    "results = {}\n",
    "trials = 5\n",
    "for nt in net_types:\n",
    "  results[nt] = []\n",
    "  for i in range(trials):\n",
    "    print('model type', nt, 'trail', i, 'starts')\n",
    "    train_losses = []\n",
    "    train_counter = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    if nt == 'M':\n",
    "      net = FastUpdateNetLarge()\n",
    "      optimizer = optim.SGD(net.get_parameters(), lr=learning_rate, momentum=momentum)\n",
    "    else:\n",
    "      net = TeacherNetLarge()\n",
    "      optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "      if nt == 'M':\n",
    "        train(epoch, net)\n",
    "      else:\n",
    "        train_teacherNet(epoch, net)\n",
    "      test(net)\n",
    "    results[nt].append({'train_losses':train_losses, 'train_counter':train_counter, 'test_losses':test_losses, 'test_accuracies':test_accuracies})\n",
    "\n",
    "# torch.save(results, './FMNIST-result.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(87.6800), tensor(86.7100), tensor(85.2100), tensor(87.9900), tensor(86.4400)]\n",
      "base tensor(86.8060) tensor(1.1018)\n",
      "[tensor(85.4800), tensor(76.0700), tensor(85.8100), tensor(84.9400), tensor(85.9600)]\n",
      "M tensor(83.6520) tensor(4.2565)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "net_types = ['base', 'M']\n",
    "results = torch.load('./FMNIST-result.pt')\n",
    "for nt in net_types:\n",
    "    total = 0\n",
    "    all_r = []\n",
    "    for r in results[nt]:\n",
    "        total = total + r['test_accuracies'][-1]\n",
    "        all_r.append(r['test_accuracies'][-1])\n",
    "    print(all_r)\n",
    "    print(nt, total / len(results[nt]), torch.std(torch.tensor(all_r), dim = 0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test using no Ms, and only on main thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_no_M(epoch, network):\n",
    "  network.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = network(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    # print(network.mNet.saver.grad)\n",
    "    # p1 = Thread(target=compute_back_M1, args=[network]) # start two independent threads\n",
    "    # # p2 = Thread(target=compute_back_M2, args=[network])\n",
    "    \n",
    "    # p1.start()\n",
    "    # # p2.start()\n",
    "    # network.mNet2.backwardHidden()\n",
    "    # p1.join() # wait for the two threads to finish\n",
    "    # # return \n",
    "    # # p2.join()\n",
    "\n",
    "    correctness = (target == torch.argmax(output))\n",
    "    optimizer.step()\n",
    "    # network.mNet.weightUpdate(correctness, lr = learning_rate)\n",
    "    if batch_idx % log_interval == 0:\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append(\n",
    "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "fNet = FastUpdateNetLarge()\n",
    "fNet.mNet1 = torch.nn.Sequential(nn.Linear(392, 196), nn.ReLU(), nn.Linear(196, 98), nn.ReLU(), nn.Linear(98, 49), nn.ReLU())\n",
    "fNet.mNet2 = torch.nn.Sequential(nn.Linear(392, 196), nn.ReLU(), nn.Linear(196, 98), nn.ReLU(), nn.Linear(98, 49), nn.ReLU())\n",
    "optimizer = optim.SGD(fNet.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3051, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.3021, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.2995, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.6677, Accuracy: 2402/10000 (24%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8659, Accuracy: 6525/10000 (65%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.0468, Accuracy: 6144/10000 (61%)\n",
      "\n",
      "Training time for 5 epochs: 49.55497955996543 seconds\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "s = time.perf_counter()\n",
    "\n",
    "test(fNet)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train_no_M(epoch, fNet)\n",
    "  test(fNet)\n",
    "  # if (epoch + 1) % 10 == 0:\n",
    "  #   torch.save(fNet, 'fNet-stdp-30000-epoch.pt')\n",
    "  #   with open('fNet-stdp-3000-epoch-loss-accuracy.pkl', 'wb') as f:\n",
    "  #     pickle.dump({'train_losses':train_losses, 'test_losses': test_losses, 'test_accuracies':test_accuracies}, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# torch.save(fNet, 'fNet-stdp-30000-epoch.pt')\n",
    "e = time.perf_counter()\n",
    "print(f\"Training time for {epoch} epochs: {e-s} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ee5443183715725406fd5246e657c0e511f90699501bc5e8c5d8d2b3c204bfa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
