{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transformer breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/pythonenvs/venv38/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transformer_model = torch.nn.Transformer(nhead=16, num_encoder_layers=12)\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(Net, self).__init__()\n",
    "        self.model = model\n",
    "        self.encoder = model.encoder # src, mask, src key padding mask\n",
    "        self.decoder = model.decoder # tgt, memory, tgt mask, memory mask, tgt key padding mask, memory key padding mask\n",
    "\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        mem = self.encoder(src) # apply M\n",
    "        output = self.decoder(tgt, mem)\n",
    "        \n",
    "        return output\n",
    "\n",
    "src = torch.rand((10, 32, 512))\n",
    "tgt = torch.rand((20, 32, 512))\n",
    "# oi = transformer_model.encoder(src)\n",
    "# of = transformer_model.decoder(oi, tgt)\n",
    "# print(oi.shape)\n",
    "# print(of.shape)\n",
    "# o1 = transformer_model(src, tgt)\n",
    "# net = Net(transformer_model)\n",
    "# o2 = net(src,tgt)\n",
    "# print('o1 ', o1.shape)\n",
    "# print('o2 ', o2.shape)\n",
    "# print(o1)\n",
    "# print(o2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerEncoderLayer(\n",
       "  (self_attn): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout1): Dropout(p=0.1, inplace=False)\n",
       "  (dropout2): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_model.encoder.layers[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WMT2014 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch Multi30k tutorial\n",
    "complete with early stopping and testing with bleu score\n",
    "only concern is that original transformer arch was not tested on multi30k but on wmt2014 instead"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try to download a mt dataset, https://pytorch.org/tutorials/beginner/translation_transformer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import multi30k, Multi30k\n",
    "from typing import Iterable, List\n",
    "import torchdata\n",
    "\n",
    "\n",
    "# We need to modify the URLs for the dataset since the links to the original dataset are broken\n",
    "# Refer to https://github.com/pytorch/text/issues/1756#issuecomment-1163664163 for more info\n",
    "multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n",
    "multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n",
    "\n",
    "SRC_LANGUAGE = 'en'\n",
    "TGT_LANGUAGE = 'de'\n",
    "\n",
    "# Place-holders\n",
    "token_transform = {}\n",
    "vocab_transform = {}\n",
    "\n",
    "\n",
    "# Create source and target language tokenizer. Make sure to install the dependencies.\n",
    "# pip install -U torchdata\n",
    "# pip install -U spacy\n",
    "# python -m spacy download en_core_web_sm\n",
    "# python -m spacy download de_core_news_sm\n",
    "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "\n",
    "# helper function to yield list of tokens\n",
    "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
    "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
    "\n",
    "    for data_sample in data_iter:\n",
    "        yield token_transform[language](data_sample[language_index[language]])\n",
    "\n",
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    # Training data Iterator\n",
    "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    # Create torchtext's Vocab object\n",
    "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
    "                                                    min_freq=1,\n",
    "                                                    specials=special_symbols,\n",
    "                                                    special_first=True)\n",
    "\n",
    "# Set UNK_IDX as the default index. This index is returned when the token is not found.\n",
    "# If not set, it throws RuntimeError when the queried token is not found in the Vocabulary.\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "  vocab_transform[ln].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vocab_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 64\n",
    "\n",
    "# train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "# train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "# ct = 0\n",
    "# for thing in enumerate(train_dataloader):\n",
    "#     # print(thing[1][0].shape, thing[1][1].shape)\n",
    "#     ct +=1 \n",
    "# NUM_BATCHES = ct\n",
    "# print(ct)\n",
    "# # thing\n",
    "NUM_BATCHES = 454 # for multi30k w bs=64"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### seq2seq transformer arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "DEVICE = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "\n",
    "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "# Seq2Seq Network\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        if False:\n",
    "            self.transformer = CustomTransformer(d_model=emb_size,\n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "        else: \n",
    "            self.transformer = Transformer(d_model=emb_size,\n",
    "                                        nhead=nhead,\n",
    "                                        num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size) # not returning the attn output weights\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                src_mask: Tensor,\n",
    "                tgt_mask: Tensor,\n",
    "                src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor,\n",
    "                memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        # print('src_emb.shape ', src_emb.shape)\n",
    "        # print('src_mask.shape ', src_mask.shape)\n",
    "        # print('src_emb ', src_emb)\n",
    "        # print('src_mask ', src_mask)\n",
    "        # exit(0)\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask) # find out how masking is applied within forward method\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 2048\n",
    "BATCH_SIZE = 64\n",
    "NUM_ENCODER_LAYERS = 6\n",
    "NUM_DECODER_LAYERS = 6\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to('cuda:1')\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX, label_smoothing=0.1)\n",
    "lr = 0.0007 \n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=lr, betas=(0.9, 0.98), eps=1e-9)\n",
    "# optimizer = torch.optim.Adam(transformer.transformer.get_parameters(), lr=lr, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    return torch.cat((torch.tensor([BOS_IDX]),\n",
    "                      torch.tensor(token_ids),\n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "# src and tgt language text transforms to convert raw strings into tensors indices\n",
    "text_transform = {}\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
    "                                               vocab_transform[ln], #Numericalization\n",
    "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "\n",
    "# function to collate data samples into batch tensors\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
    "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LARGE_BATCH_SIZE = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from threading import Thread\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "def update_lr(step_num):\n",
    "    num_warmup = 4000\n",
    "    return (EMB_SIZE)**-0.5 * min(step_num**(-0.5), step_num * num_warmup**(-1.5))\n",
    "\n",
    "def train_epoch(model, optimizer):\n",
    "    # print('epoch, ', epoch)\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    saved_losses = []\n",
    "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "    step = 1\n",
    "    minibatch_counter = 0\n",
    "    for src, tgt in train_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        # if src.shape[1] != BATCH_SIZE:\n",
    "        #     print('not skipping batch of size ',src.shape[1])\n",
    "        #     # continue \n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        # optimizer.zero_grad()\n",
    "        step_num = int((epoch-1) * (NUM_BATCHES // LARGE_BATCH_SIZE)) + step # FIXME: is this right?\n",
    "        # if epoch > 1 and step == 0:\n",
    "        #     step_num = epoch * NUM_BATCHES\n",
    "        # optimizer.param_groups[0]['lr'] = update_lr(step_num)\n",
    "        \n",
    "        \n",
    "        # print('updated lr: ', optimizer.param_groups[0]['lr'])\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward() # FIXME: does the .backward() continue to accumlate gradient?\n",
    "\n",
    "        # optimizer.step()\n",
    "        losses += loss.item()\n",
    "        saved_losses.append(loss.item())\n",
    "        # step += 1 # each minibatch of data is considered 1 step  -- false each larger BATCH should be consider one step\n",
    "        minibatch_counter += 1\n",
    "\n",
    "        if minibatch_counter > LARGE_BATCH_SIZE - 1: \n",
    "            minibatch_counter = 0\n",
    "            # update the lr and the weights\n",
    "            # print(step)\n",
    "            # print((NUM_BATCHES // LARGE_BATCH_SIZE))\n",
    "            # print(epoch-1)\n",
    "            # print(int(epoch-1 * (NUM_BATCHES / LARGE_BATCH_SIZE)) + step)\n",
    "            # print(int((epoch-1) * (NUM_BATCHES / LARGE_BATCH_SIZE)) + 0)\n",
    "            # print( int(epoch * (NUM_BATCHES / LARGE_BATCH_SIZE)) + step )\n",
    "\n",
    "            # print(type(step_num))\n",
    "            # print((step_num))\n",
    "            optimizer.param_groups[0]['lr'] = update_lr(step_num)\n",
    "            optimizer.step()\n",
    "            # reset grad\n",
    "            optimizer.zero_grad()\n",
    "            step += 1\n",
    "\n",
    "        \n",
    "    # update lr and weights as long as they weren't JUST updated\n",
    "    if minibatch_counter > 0:\n",
    "        # update the lr and the weights\n",
    "        optimizer.param_groups[0]['lr'] = update_lr(step_num)\n",
    "        optimizer.step()\n",
    "        # reset grad\n",
    "        optimizer.zero_grad()\n",
    "        step += 1\n",
    "\n",
    "    # step += 1\n",
    "    return losses / len(list(train_dataloader)), saved_losses\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "    saved_losses_val = []\n",
    "    val_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "    for src, tgt in val_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "        saved_losses_val.append(loss.item())\n",
    "\n",
    "    return losses / len(list(val_dataloader)), saved_losses_val"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer.load_state_dict(torch.load(PATH))\n",
    "sd = torch.load(PATH).state_dict()\n",
    "torch.save(sd, 'BASELINE_transformer_n=6_minibatching_goodBLEU_weights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer model weights loaded\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "NUM_EPOCHS = 120 # 220 with batch size of 64 corresponds to just under 100k training steps (like in attn paper)\n",
    "DEVICE = 'cuda:1'\n",
    "PATH = 'BASELINE_transformer_n=6_minibatching_goodBLEU_weights.pt'\n",
    "best_model = None\n",
    "try:\n",
    "    # raise Exception\n",
    "    transformer.load_state_dict(torch.load(PATH))\n",
    "    best_model = transformer\n",
    "    print('Transformer model weights loaded')\n",
    "except Exception:\n",
    "    print('not loaded, retraining')\n",
    "    # exit()\n",
    "    # early_stopper = EarlyStopper(patience=3, min_delta=0.025)\n",
    "    t0 = time.time()\n",
    "    training_losses_to_plot = []\n",
    "    val_losses_to_plot = []\n",
    "    optimizer.param_groups[0]['lr'] = update_lr(1)\n",
    "    for epoch in range(1, NUM_EPOCHS+1):\n",
    "        start_time = timer()\n",
    "        # train_loss, saved_losses_train = train_epoch_parallel(transformer, optimizer)\n",
    "        train_loss, saved_losses_train = train_epoch(transformer, optimizer)\n",
    "        end_time = timer()\n",
    "        val_loss, saved_losses_val = evaluate(transformer)\n",
    "\n",
    "        print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "        lst_sqs_sum = 0\n",
    "        if len(val_losses_to_plot) > 0 and val_loss < min(val_losses_to_plot):\n",
    "            best_model = transformer\n",
    "            torch.save(best_model.state_dict(), 'tmp_transformer_base_weights.pt')\n",
    "            # keep the model with lowest val loss\n",
    "        \n",
    "        \n",
    "        training_losses_to_plot.append(train_loss)\n",
    "        val_losses_to_plot.append(val_loss)\n",
    "        \n",
    "\n",
    "        # if early_stopper.early_stop(val_loss):\n",
    "        #     print(\"<EARLY STOP> model done training.\")             \n",
    "        #     break\n",
    "    tf = time.time()\n",
    "    PATH = f'ORG_seq2seq_transformer_multi30k_weights_epochs={epoch}.pt'\n",
    "    torch.save(transformer.state_dict(), PATH)\n",
    "    print(f'Transformer model saved ({PATH})')\n",
    "    print(f'Trained for {NUM_EPOCHS} epochs in {tf - t0} seconds')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve training further, can use adaptive learning rate schedule as described in sec 5.3 and also label smoothing as described in sec 5.4 - now implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_model is not None:\n",
    "    transformer = best_model\n",
    "    torch.save(transformer, 'BASELINE_transformer_n=6_minibatching_goodBLEU.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total num steps:  54480\n"
     ]
    }
   ],
   "source": [
    "print(\"total num steps: \", NUM_EPOCHS * NUM_BATCHES)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "s = (len(training_losses_to_plot) // len(val_losses_to_plot)) \n",
    "\n",
    "# plt.plot(np.arange(0, len(training_losses_to_plot), 10), training_losses_to_plot[::10])\n",
    "plt.plot(range(NUM_EPOCHS), training_losses_to_plot, label='Training')\n",
    "plt.plot(range(NUM_EPOCHS), val_losses_to_plot, label='Validation')\n",
    "plt.legend()\n",
    "plt.ylabel(\"Cross Entropy Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import bleu_score\n",
    "\n",
    "# function to generate output sequence using greedy algorithm\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "# function to generate output sequence using greedy algorithm\n",
    "def greedy_decode_MNet(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "    # print(src.shape)\n",
    "    src_emb = model.positional_encoding(model.src_tok_emb(src))\n",
    "    # print(src_emb.shape)\n",
    "    memory = model.transformer.custom_encode(src_emb, src_mask, None)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        ys_emb = model.positional_encoding(model.tgt_tok_emb(ys))\n",
    "        out = model.transformer.model.decoder(ys_emb, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "# actual function to translate input sentence into target language\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()\n",
    "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n",
    "\n",
    "# actual function to translate input sentence into target language\n",
    "def translate_MNet(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()\n",
    "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "    # print('in translate, ', src.shape)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode_MNet(\n",
    "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n",
    "\n",
    "def test(model,):\n",
    "    test_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    \n",
    "    # compute the avg bleu score\n",
    "    bleu = 0\n",
    "    ct = 0\n",
    "    for data_sample in test_iter:\n",
    "        ct += 1\n",
    "        # print(data_sample)\n",
    "        src = data_sample[0]\n",
    "        tgt = data_sample[1]\n",
    "        pred = translate(model, src)\n",
    "        bleu += bleu_score([pred], [tgt])\n",
    "    return bleu / ct\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "references = [['this', 'is' 'test']]\n",
    "candidates = [['this', 'is', 'a', 'test']]\n",
    "score = corpus_bleu(references, candidates)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/pythonenvs/venv38/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "# transformer.load_state_dict(torch.load('seq2seq_transformer_multi30k_weights_epochs=21.pt'))\n",
    "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu\n",
    "test_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "de = []\n",
    "en = []\n",
    "de_preds = []\n",
    "sentence_scores = []\n",
    "for data_sample in test_iter:\n",
    "    if len(data_sample[0]) < 3 or len(data_sample[1]) < 3:\n",
    "        print('here')\n",
    "        continue\n",
    "    \n",
    "    en.append(data_sample[0].split())\n",
    "    de.append(data_sample[1].split())\n",
    "    \n",
    "    pred = translate(transformer, data_sample[0])\n",
    "    pred_split = pred.split()\n",
    "    # if pred_split[-1] == '.':\n",
    "    #     pred_split = pred_split[:-1] # trim periods\n",
    "    de_preds.append(pred_split)\n",
    "    sentence_scores.append(sentence_bleu(de[-1], pred_split))\n",
    "\n",
    "\n",
    "\n",
    "# score = sentence_bleu(de, de_preds) # compare true de with pred de\n",
    "# score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg BLEU EN->DE scores: \n",
      "0.30497300137458444\n"
     ]
    }
   ],
   "source": [
    "print('avg BLEU EN->DE scores: ')\n",
    "\n",
    "print(sum(sentence_scores) / len(sentence_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Eine', 'Gruppe', 'von', 'Mnnern', 'ldt', 'Baumwolle', 'auf', 'einen', 'Lastwagen'], ['Ein', 'Mann', 'schlft', 'in', 'einem', 'grnen', 'Raum', 'auf', 'einem', 'Sofa.'], ['Ein', 'Junge', 'mit', 'Kopfhrern', 'sitzt', 'auf', 'den', 'Schultern', 'einer', 'Frau.'], ['Zwei', 'Mnner', 'bauen', 'eine', 'blaue', 'Eisfischerhtte', 'auf', 'einem', 'zugefrorenen', 'See', 'auf'], ['Ein', 'Mann', 'mit', 'beginnender', 'Glatze,', 'der', 'eine', 'rote', 'Rettungsweste', 'trgt,', 'sitzt', 'in', 'einem', 'kleinen', 'Boot.']]\n",
      "[['Eine', 'Gruppe', 'Mnner', 'ist', 'Zuckerwatte', 'versammelt', 'sich', 'der', 'sich', 'um', 'einen', 'Lkw', 'bewegt', '.'], ['Ein', 'schlafender', 'Mann', 'in', 'einem', 'grnen', 'Raum', 'auf', 'einem', 'Sofa', '.'], ['Ein', 'Junge', 'mit', 'Kopfhrer', 'sitzt', 'auf', 'den', 'Schultern', 'einer', 'Frau', '.'], ['Zwei', 'Mnner', 'bauen', 'einen', 'blauen', 'Tanz', 'auf', 'einem', 'Eistee', 'ber', 'ein', 'See', 'ber', 'einen', 'See', '.'], ['Ein', 'kahl', 'werdender', 'Mann', 'mit', 'einer', 'roten', 'Schwimmweste', 'sitzt', 'in', 'einem', 'kleinen', 'Boot', '.']]\n"
     ]
    }
   ],
   "source": [
    "print(de[0:5])\n",
    "print(de_preds[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(transformer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hinter einem Gehsteig fahren eine genaue Aufzhlung von allem , was ich hier kommen .\n",
      " Karatekurs ist bereit zu Besuch . \n",
      " Stdtische Baumarbeiter sind in dem Kopf aufgehngt . \n"
     ]
    }
   ],
   "source": [
    "print(translate(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\"))\n",
    "print(translate(transformer, \"Wie gehen Sie?\"))\n",
    "print(translate(transformer, \"Ich heisse Hermann\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score for ref_corpus: [['A group of people stand in front of an igloo']], score: 0.8801117539405823\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# A group of people stand in front of an auditorium\n",
    "# candidate_corpus = [['A', 'group', 'of', 'people', 'stand', 'in', 'front', 'of', 'an', 'auditorium'], ['Wie', 'gehen', 'Sie']]\n",
    "candidate_corpus = ['A group of people stand in front of an auditorium']\n",
    "# references_corpus = [['A', 'group', 'of', 'people', 'stand', 'in', 'front', 'of', 'an', 'igloo'], ['How', 'are', 'you'], ['No', 'Match']]\n",
    "references_corpus = [['A group of people stand in front of an igloo']]\n",
    "score = bleu_score(candidate_corpus, references_corpus)\n",
    "print(f'BLEU score for ref_corpus: {references_corpus}, score: {score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ee5443183715725406fd5246e657c0e511f90699501bc5e8c5d8d2b3c204bfa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
